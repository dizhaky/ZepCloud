# Docker Compose Configuration for M365 RAG System
# Elasticsearch + RAG-Anything + RAGFlow on Hetzner AX52
# Version: 1.0.0

version: '3.8'

networks:
  rag-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16

volumes:
  es-data:
  pg-data:
  redis-data:
  minio-data:
  ragflow-data:

services:
  # ============================================
  # ELASTICSEARCH - Vector Search Engine
  # ============================================
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0
    container_name: elasticsearch
    environment:
      - node.name=es-node-1
      - cluster.name=m365-rag-cluster
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms16g -Xmx16g"
      - xpack.security.enabled=true
      - xpack.security.http.ssl.enabled=true  # âœ… SSL enabled for security
      - xpack.security.http.ssl.key=/usr/share/elasticsearch/config/certs/elasticsearch.key
      - xpack.security.http.ssl.certificate=/usr/share/elasticsearch/config/certs/elasticsearch.crt
      - xpack.security.http.ssl.certificate_authorities=/usr/share/elasticsearch/config/certs/ca.crt
      - xpack.security.http.ssl.verification_mode=certificate
      - xpack.security.transport.ssl.enabled=true
      - xpack.security.transport.ssl.key=/usr/share/elasticsearch/config/certs/elasticsearch.key
      - xpack.security.transport.ssl.certificate=/usr/share/elasticsearch/config/certs/elasticsearch.crt
      - xpack.security.transport.ssl.certificate_authorities=/usr/share/elasticsearch/config/certs/ca.crt
      - xpack.security.transport.ssl.verification_mode=certificate
      - xpack.ml.enabled=true
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD:-changeme}
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - es-data:/usr/share/elasticsearch/data
      - ./config/elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro
      - ./config/elasticsearch/certs:/usr/share/elasticsearch/config/certs:ro
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      rag-network:
        ipv4_address: 172.28.0.10
    healthcheck:
      test: ["CMD-SHELL", "curl -k -s -u elastic:${ELASTIC_PASSWORD:-changeme} https://localhost:9200/_cluster/health | grep -q '\"status\":\"green\"\\|\"status\":\"yellow\"'"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 18G
        reservations:
          memory: 16G

  # ============================================
  # POSTGRESQL - Metadata & User Database
  # ============================================
  postgres:
    image: pgvector/pgvector:pg16
    container_name: postgres
    environment:
      - POSTGRES_DB=m365_rag
      - POSTGRES_USER=${POSTGRES_USER:-raguser}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-changeme}
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      - pg-data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql:ro
    ports:
      - "5432:5432"
    networks:
      rag-network:
        ipv4_address: 172.28.0.11
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-raguser}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G

  # ============================================
  # REDIS - Cache Layer
  # ============================================
  redis:
    image: redis:7-alpine
    container_name: redis
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
    volumes:
      - redis-data:/data
    ports:
      - "6379:6379"
    networks:
      rag-network:
        ipv4_address: 172.28.0.12
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  # ============================================
  # MinIO - Object Storage
  # ============================================
  minio:
    image: minio/minio:latest
    container_name: minio
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-changeme123}
    volumes:
      - minio-data:/data
    ports:
      - "9000:9000"  # API
      - "9001:9001"  # Console
    networks:
      rag-network:
        ipv4_address: 172.28.0.13
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  # ============================================
  # RAGFlow - Production RAG UI & Workflow Engine
  # ============================================
  ragflow:
    image: infiniflow/ragflow:latest
    container_name: ragflow
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-raguser}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-changeme}
      - POSTGRES_DB=ragflow
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - ES_HOST=elasticsearch
      - ES_PORT=9200
      - ES_USER=elastic
      - ES_PASSWORD=${ELASTIC_PASSWORD:-changeme}
      - MINIO_HOST=minio
      - MINIO_PORT=9000
      - MINIO_USER=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_PASSWORD=${MINIO_ROOT_PASSWORD:-changeme123}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - SECRET_KEY=${RAGFLOW_SECRET_KEY:-your-secret-key-here}
    volumes:
      - ragflow-data:/ragflow/data
      - ./config/ragflow:/ragflow/conf
    ports:
      - "9380:9380"  # RAGFlow UI
    networks:
      rag-network:
        ipv4_address: 172.28.0.14
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      minio:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9380/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G

  # ============================================
  # CUSTOM API - Integration Layer
  # ============================================
  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    container_name: m365-rag-api
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-raguser}:${POSTGRES_PASSWORD:-changeme}@postgres:5432/m365_rag
      - REDIS_URL=redis://redis:6379
      - ES_HOST=elasticsearch
      - ES_PORT=9200
      - ES_USER=elastic
      - ES_PASSWORD=${ELASTIC_PASSWORD:-changeme}
      - ES_USE_SSL=true
      - ES_VERIFY_CERTS=false  # Self-signed certs in Docker network
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_SECRET_KEY=${MINIO_ROOT_PASSWORD:-changeme123}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      # M365 Authentication (fallback handled in config_manager.py)
      - M365_CLIENT_ID=${M365_CLIENT_ID}
      - M365_CLIENT_SECRET=${M365_CLIENT_SECRET}
      - M365_TENANT_ID=${M365_TENANT_ID}
      - AZURE_CLIENT_ID=${AZURE_CLIENT_ID}
      - AZURE_CLIENT_SECRET=${AZURE_CLIENT_SECRET}
      - AZURE_TENANT_ID=${AZURE_TENANT_ID}
      - M365_USE_DELEGATED_AUTH=${M365_USE_DELEGATED_AUTH:-true}
      - JWT_SECRET=${JWT_SECRET:-your-jwt-secret}
      - ENVIRONMENT=production
    volumes:
      - ./api:/app
      - ./config/rag-anything:/app/config
    ports:
      - "8000:8000"
    networks:
      rag-network:
        ipv4_address: 172.28.0.15
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      minio:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G

  # ============================================
  # NGINX - Reverse Proxy & Load Balancer
  # ============================================
  nginx:
    image: nginx:alpine
    container_name: nginx
    volumes:
      - ./config/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./config/nginx/ssl:/etc/nginx/ssl:ro
      - ./static:/usr/share/nginx/html:ro
    ports:
      - "80:80"
      - "443:443"
    networks:
      rag-network:
        ipv4_address: 172.28.0.20
    depends_on:
      - ragflow
      - api
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # ============================================
  # PROMETHEUS - Monitoring
  # ============================================
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./config/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./data/prometheus:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
    ports:
      - "9090:9090"
    networks:
      rag-network:
        ipv4_address: 172.28.0.30
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # ============================================
  # GRAFANA - Visualization
  # ============================================
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-changeme}
      - GF_INSTALL_PLUGINS=
    volumes:
      - ./data/grafana:/var/lib/grafana
      - ./config/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./config/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    ports:
      - "3000:3000"
    networks:
      rag-network:
        ipv4_address: 172.28.0.31
    depends_on:
      - prometheus
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # ============================================
  # ELASTICSEARCH EXPORTER - Metrics
  # ============================================
  elasticsearch-exporter:
    image: quay.io/prometheuscommunity/elasticsearch-exporter:latest
    container_name: elasticsearch-exporter
    command:
      - '--es.uri=https://elastic:${ELASTIC_PASSWORD:-changeme}@elasticsearch:9200'
      - '--es.all'
      - '--es.indices'
      - '--es.shards'
      - '--es.ssl-skip-verify'  # Skip verification for self-signed certs
    ports:
      - "9114:9114"
    networks:
      rag-network:
        ipv4_address: 172.28.0.32
    depends_on:
      - elasticsearch
    restart: unless-stopped

# ============================================
# RESOURCE ALLOCATION SUMMARY
# ============================================
# Elasticsearch:  16GB RAM
# PostgreSQL:     4GB RAM  
# Redis:          2GB RAM
# MinIO:          2GB RAM
# RAGFlow:        8GB RAM
# API:            4GB RAM
# Nginx:          512MB RAM
# Prometheus:     1GB RAM
# Grafana:        512MB RAM
# ============================================
# TOTAL:          ~38GB RAM (90GB available on AX52)
# ============================================

