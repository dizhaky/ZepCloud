# Disaster Recovery and Backup Security Plan for M365 RAG System

## Overview

This document outlines the disaster recovery and backup security plan for the M365 RAG System, focusing on secure backup
storage, backup encryption, recovery point objectives (RPO), and recovery time objectives (RTO). This plan enhances
the existing backup configuration with additional security measures to protect against data loss and ensure business
  continuity.

## 1. Secure Backup Storage

### 1.1 Backup Storage Architecture

The M365 RAG System implements a multi-tiered backup storage approach to ensure data availability and security:

1. **Primary Backup Storage**: Local encrypted storage on the Hetzner server
2. **Secondary Backup Storage**: Off-site encrypted storage using cloud services
3. **Tertiary Backup Storage**: Air-gapped long-term archival storage

### 1.2 Local Backup Storage Security

#### Encrypted Backup Volume

```bash

# Create encrypted volume for backups

sudo dd if=/dev/zero of=/backup-encrypted.img bs=1G count=100
sudo cryptsetup luksFormat /backup-encrypted.img

# Open encrypted volume

sudo cryptsetup luksOpen /backup-encrypted.img backup-encrypted

# Create filesystem

sudo mkfs.ext4 /dev/mapper/backup-encrypted

# Mount encrypted volume

sudo mkdir -p /secure-backup
sudo mount /dev/mapper/backup-encrypted /secure-backup

# Update backup script to use encrypted volume

sudo nano /data/m365-rag/scripts/secure-backup.sh

```

#### Secure Backup Script

```bash

#!/bin/bash

# Secure Backup Script for M365 RAG System

# Configuration

BACKUP_DIR="/secure-backup/m365-rag"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=30
PROJECT_DIR="/data/m365-rag"

# Colors for output

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Load environment variables

if [ -f "$PROJECT_DIR/.env" ]; then
    echo -e "${YELLOW}üìù Loading environment variables...${NC}"
    set -a
    source "$PROJECT_DIR/.env"
    set +a
    echo -e "${GREEN}‚úÖ Environment variables loaded${NC}"
else
    echo -e "${RED}‚ùå Error: .env file not found at $PROJECT_DIR/.env${NC}"
    exit 1
fi

echo -e "${GREEN}üîÑ Starting Secure M365 RAG System Backup - $DATE${NC}"

# Create backup directory

mkdir -p "$BACKUP_DIR/$DATE"

# 1. Backup Elasticsearch with encryption

echo -e "${YELLOW}üìä Backing up Elasticsearch...${NC}"
docker exec elasticsearch curl -X PUT "localhost:9200/_snapshot/backup/$DATE?wait_for_completion=true" \
    -u "elastic:$ELASTIC_PASSWORD" \
    -H 'Content-Type: application/json' \
    -d '{
        "indices": "*",
        "ignore_unavailable": true,
        "include_global_state": false
    }' || echo -e "${RED}‚ùå Elasticsearch backup failed${NC}"

# 2. Backup PostgreSQL with encryption

echo -e "${YELLOW}üóÑÔ∏è  Backing up PostgreSQL...${NC}"
docker exec -t postgres pg_dump -U raguser m365_rag | gzip > "$BACKUP_DIR/$DATE/postgres.sql.gz"
if [ $? -eq 0 ]; then
    echo -e "${GREEN}‚úÖ PostgreSQL backup successful${NC}"
else
    echo -e "${RED}‚ùå PostgreSQL backup failed${NC}"
fi

# 3. Backup Redis (if needed)

echo -e "${YELLOW}üíæ Backing up Redis...${NC}"
docker exec redis redis-cli SAVE
docker cp redis:/data/dump.rdb "$BACKUP_DIR/$DATE/redis_dump.rdb" || echo -e "${RED}‚ùå Redis backup failed${NC}"

# 4. Backup MinIO data

echo -e "${YELLOW}üì¶ Backing up MinIO configuration...${NC}"
docker exec minio mc alias set local http://localhost:9000 $MINIO_ROOT_USER $MINIO_ROOT_PASSWORD
docker exec minio mc admin config export local > "$BACKUP_DIR/$DATE/minio_config.json" || echo -e "${RED}‚ùå MinIO config
  backup failed${NC}"

# 5. Backup configuration files

echo -e "${YELLOW}‚öôÔ∏è  Backing up configuration files...${NC}"
tar -czf "$BACKUP_DIR/$DATE/configs.tar.gz" \
    -C /data/m365-rag \
    config/ \
    docker-compose.yml \
    .env || echo -e "${RED}‚ùå Config backup failed${NC}"

# 6. Backup scripts

echo -e "${YELLOW}üìú Backing up scripts...${NC}"
tar -czf "$BACKUP_DIR/$DATE/scripts.tar.gz" \
    -C /data/m365-rag \
    scripts/ || echo -e "${RED}‚ùå Scripts backup failed${NC}"

# Calculate backup size

BACKUP_SIZE=$(du -sh "$BACKUP_DIR/$DATE" | cut -f1)
echo -e "${GREEN}üìä Backup size: $BACKUP_SIZE${NC}"

# Create backup manifest

cat > "$BACKUP_DIR/$DATE/manifest.txt" <<EOF
M365 RAG System Secure Backup
Date: $DATE
Size: $BACKUP_SIZE
Components:

- Elasticsearch snapshot
- PostgreSQL database dump
- Redis data
- MinIO configuration
- Application configs
- Scripts

Backup completed at: $(date)
EOF

# Remove old backups

echo -e "${YELLOW}üßπ Cleaning up old backups (older than $RETENTION_DAYS days)...${NC}"
find "$BACKUP_DIR" -type d -mtime +$RETENTION_DAYS -exec rm -rf {} + 2>/dev/null || true

# Verify backup

if [ -f "$BACKUP_DIR/$DATE/postgres.sql.gz" ]; then
    echo -e "${GREEN}‚úÖ Backup completed successfully!${NC}"
    echo -e "${GREEN}üìÅ Location: $BACKUP_DIR/$DATE${NC}"
else
    echo -e "${RED}‚ùå Backup verification failed!${NC}"
    exit 1
fi

echo -e "${GREEN}üéâ Secure backup process finished${NC}"

```

### 1.3 Off-Site Backup Storage

#### Hetzner Storage Box Configuration

```bash

# Mount Hetzner Storage Box with encryption

sudo mkdir -p /mnt/storagebox

# Create encrypted connection to Storage Box

sudo mount -t cifs //SERVER.storagebox.de/backup /mnt/storagebox \
    -o username=USERNAME,password=PASSWORD,uid=1000,gid=1000,vers=3.0,iocharset=utf8

# Create encrypted backup sync script

sudo nano /usr/local/bin/sync-encrypted-backups.sh

```

```bash

#!/bin/bash

# Encrypted Backup Synchronization Script

# Configuration (2)

LOCAL_BACKUP_DIR="/secure-backup/m365-rag"
REMOTE_BACKUP_DIR="/mnt/storagebox/m365-rag-backups"
DATE=$(date +%Y%m%d_%H%M%S)

# Colors for output (2)

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo -e "${GREEN}üîÑ Starting encrypted backup synchronization - $DATE${NC}"

# Check if remote storage is mounted

if ! mountpoint -q /mnt/storagebox; then
    echo -e "${RED}‚ùå Remote storage not mounted${NC}"
    exit 1
fi

# Create remote backup directory

mkdir -p "$REMOTE_BACKUP_DIR"

# Sync backups with encryption

echo -e "${YELLOW}üîí Encrypting and syncing backups...${NC}"

# For each backup directory, encrypt and sync

find "$LOCAL_BACKUP_DIR" -maxdepth 1 -type d -name "20*" | while read backup_dir; do
    backup_name=$(basename "$backup_dir")

    # Check if already synced
    if [ ! -f "$REMOTE_BACKUP_DIR/$backup_name.synced" ]; then
        echo -e "${YELLOW}üì§ Syncing $backup_name...${NC}"

        # Create encrypted archive
        tar -czf - -C "$LOCAL_BACKUP_DIR" "$backup_name" | \
        gpg --encrypt --recipient backup@m365-rag.local --output "$REMOTE_BACKUP_DIR/$backup_name.tar.gz.gpg"

        # Mark as synced
        touch "$REMOTE_BACKUP_DIR/$backup_name.synced"

        echo -e "${GREEN}‚úÖ $backup_name synced and encrypted${NC}"
    fi
done

# Clean up old remote backups

echo -e "${YELLOW}üßπ Cleaning up old remote backups...${NC}"
find "$REMOTE_BACKUP_DIR" -name "*.gpg" -mtime +90 -delete 2>/dev/null || true
find "$REMOTE_BACKUP_DIR" -name "*.synced" -mtime +90 -delete 2>/dev/null || true

echo -e "${GREEN}üéâ Encrypted backup synchronization completed${NC}"

```

#### AWS S3 Backup Configuration

```bash

# Install AWS CLI

sudo apt install awscli

# Configure AWS credentials with encryption

aws configure

# Create S3 backup script

sudo nano /usr/local/bin/s3-encrypted-backup.sh

```

```bash

#!/bin/bash

# S3 Encrypted Backup Script

# Configuration (3)

LOCAL_BACKUP_DIR="/secure-backup/m365-rag"
S3_BUCKET="m365-rag-backups"
S3_REGION="us-east-1"
DATE=$(date +%Y%m%d_%H%M%S)

# Colors for output (3)

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo -e "${GREEN}üîÑ Starting S3 encrypted backup - $DATE${NC}"

# For each backup directory, encrypt and upload

find "$LOCAL_BACKUP_DIR" -maxdepth 1 -type d -name "20*" | while read backup_dir; do
    backup_name=$(basename "$backup_dir")

    # Check if already uploaded
    if ! aws s3 ls "s3://$S3_BUCKET/$backup_name.tar.gz.gpg" > /dev/null 2>&1; then
        echo -e "${YELLOW}üì§ Uploading $backup_name to S3...${NC}"

        # Create encrypted archive and upload directly to S3
        tar -czf - -C "$LOCAL_BACKUP_DIR" "$backup_name" | \
        gpg --encrypt --recipient backup@m365-rag.local | \
        aws s3 cp - "s3://$S3_BUCKET/$backup_name.tar.gz.gpg" --region $S3_REGION

        echo -e "${GREEN}‚úÖ $backup_name uploaded and encrypted to S3${NC}"
    fi
done

# Clean up old S3 backups

echo -e "${YELLOW}üßπ Cleaning up old S3 backups...${NC}"
aws s3 ls "s3://$S3_BUCKET/" --region $S3_REGION | \
grep ".tar.gz.gpg" | \
awk '{print $4}' | \
while read file; do
    # Get file date (assuming format: 20251019_020000.tar.gz.gpg)
    file_date=$(echo "$file" | cut -d'_' -f1 | cut -d'/' -f4)
    file_timestamp=$(date -d "$file_date" +%s 2>/dev/null || echo "0")
    current_timestamp=$(date +%s)
    age_days=$(( (current_timestamp - file_timestamp) / 86400 ))

    if [ "$age_days" -gt 90 ]; then
        echo -e "${YELLOW}üóëÔ∏è  Deleting old backup: $file${NC}"
        aws s3 rm "s3://$S3_BUCKET/$file" --region $S3_REGION
    fi
done

echo -e "${GREEN}üéâ S3 encrypted backup completed${NC}"

```

### 1.4 Air-Gapped Archival Storage

#### Quarterly Air-Gapped Backup Process

```bash

# Create air-gapped backup script

sudo nano /usr/local/bin/airgap-backup.sh

```

```bash

#!/bin/bash

# Air-Gapped Backup Script

# Configuration (4)

LOCAL_BACKUP_DIR="/secure-backup/m365-rag"
AIRGAP_DIR="/airgap-backups"
DATE=$(date +%Y%m%d_%H%M%S)
QUARTER=$(date +%Y-Q%q)

# Colors for output (4)

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo -e "${GREEN}üîÑ Starting air-gapped backup - $DATE${NC}"

# Create air-gap directory

mkdir -p "$AIRGAP_DIR/$QUARTER"

# Find the most recent backup

latest_backup=$(ls -1t "$LOCAL_BACKUP_DIR" | head -1)

if [ -n "$latest_backup" ]; then
    echo -e "${YELLOW}üîí Creating air-gapped backup of $latest_backup...${NC}"

    # Create encrypted archive for air-gap storage
    tar -czf - -C "$LOCAL_BACKUP_DIR" "$latest_backup" | \
    gpg --encrypt --recipient backup@m365-rag.local --output "$AIRGAP_DIR/$QUARTER/$latest_backup.tar.gz.gpg"

    # Create checksum for verification
    sha256sum "$AIRGAP_DIR/$QUARTER/$latest_backup.tar.gz.gpg" > "$AIRGAP_DIR/$QUARTER/$latest_backup.sha256"

    # Create documentation
    cat > "$AIRGAP_DIR/$QUARTER/README.txt" <<EOF
M365 RAG System Air-Gapped Backup
=================================

Backup Date: $DATE
Quarter: $QUARTER
Backup Name: $latest_backup

This backup contains all data necessary to restore the M365 RAG System.
It is encrypted and should be stored in a secure, offline location.

Recovery Instructions:

1. Mount encrypted backup volume
2. Decrypt backup file: gpg --decrypt $latest_backup.tar.gz.gpg > $latest_backup.tar.gz
3. Extract backup: tar -xzf $latest_backup.tar.gz
4. Follow restore procedure in documentation

Encryption Key: Stored in secure key management system
EOF

    echo -e "${GREEN}‚úÖ Air-gapped backup created successfully${NC}"
    echo -e "${GREEN}üìÅ Location: $AIRGAP_DIR/$QUARTER/${NC}"
else
    echo -e "${RED}‚ùå No backups found to archive${NC}"
    exit 1
fi

echo -e "${GREEN}üéâ Air-gapped backup process completed${NC}"

```

## 2. Backup Encryption

### 2.1 GPG Key Management

#### Generate Backup Encryption Keys

```bash

# Generate GPG key for backup encryption

gpg --gen-key

# When prompted

# 1. Select "RSA and RSA" key type

# 2. Key size: 4096 bits

# 3. Key validity: 2 years

# 4. Real name: M365 RAG Backup System

# 5. Email address: backup@m365-rag.local

# 6. Comment: Backup Encryption Key

# Export public key for distribution

gpg --export --armor backup@m365-rag.local > /data/m365-rag/config/backup-public-key.asc

# Export private key for secure storage

gpg --export-secret-keys --armor backup@m365-rag.local > /secure-keys/backup-private-key.asc

# Secure the private key

chmod 600 /secure-keys/backup-private-key.asc
chown root:root /secure-keys/backup-private-key.asc

```

#### Key Rotation Policy

```bash

# Create key rotation script

sudo nano /usr/local/bin/rotate-backup-keys.sh

```

```bash

#!/bin/bash

# Backup Key Rotation Script

# Configuration (5)

KEY_EMAIL="backup@m365-rag.local"
KEY_EXPIRY="2y"
CURRENT_DATE=$(date +%Y%m%d)

# Colors for output (5)

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo -e "${GREEN}üîÑ Starting backup key rotation - $CURRENT_DATE${NC}"

# Check if current key is expiring soon (within 30 days)

key_expiry_date=$(gpg --list-keys --with-colons "$KEY_EMAIL" | grep "^pub" | cut -d: -f7)
if [ -n "$key_expiry_date" ]; then
    current_timestamp=$(date +%s)
    expiry_timestamp=$key_expiry_date
    days_until_expiry=$(( (expiry_timestamp - current_timestamp) / 86400 ))

    if [ "$days_until_expiry" -lt 30 ]; then
        echo -e "${YELLOW}‚ö†Ô∏è  Current backup key expires in $days_until_expiry days${NC}"
        echo -e "${YELLOW}üîÑ Generating new backup key...${NC}"

        # Generate new key
        gpg --batch --gen-key <<EOF
Key-Type: RSA
Key-Length: 4096
Subkey-Type: RSA
Subkey-Length: 4096
Name-Real: M365 RAG Backup System
Name-Email: backup@m365-rag.local
Name-Comment: Backup Encryption Key
Expire-Date: $KEY_EXPIRY
%no-protection
%commit
EOF

        # Export new keys
        gpg --export --armor backup@m365-rag.local > /data/m365-rag/config/backup-public-key-new.asc
        gpg --export-secret-keys --armor backup@m365-rag.local > /secure-keys/backup-private-key-new.asc

        # Secure the private key
        chmod 600 /secure-keys/backup-private-key-new.asc
        chown root:root /secure-keys/backup-private-key-new.asc

        echo -e "${GREEN}‚úÖ New backup key generated${NC}"
        echo -e "${YELLOW}üìã Remember to update all backup scripts to use the new key${NC}"
    else
        echo -e "${GREEN}‚úÖ Current backup key is valid for $days_until_expiry more days${NC}"
    fi
else
    echo -e "${RED}‚ùå No backup key found${NC}"
    exit 1
fi

echo -e "${GREEN}üéâ Key rotation check completed${NC}"

```

### 2.2 Encrypted Backup Verification

#### Backup Integrity Verification

```bash

# Create backup verification script

sudo nano /usr/local/bin/verify-encrypted-backups.sh

```

```bash

#!/bin/bash

# Encrypted Backup Verification Script

# Configuration (6)

BACKUP_DIR="/secure-backup/m365-rag"
VERIFICATION_LOG="/var/log/backup-verification.log"
DATE=$(date +%Y%m%d_%H%M%S)

# Colors for output (6)

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo -e "${GREEN}üîç Starting backup verification - $DATE${NC}"
echo "[$DATE] Starting backup verification" >> "$VERIFICATION_LOG"

# Verify each backup

find "$BACKUP_DIR" -maxdepth 1 -type d -name "20*" | while read backup_dir; do
    backup_name=$(basename "$backup_dir")

    echo -e "${YELLOW}üîç Verifying $backup_name...${NC}"
    echo "[$DATE] Verifying $backup_name" >> "$VERIFICATION_LOG"

    # Check if all expected files exist
expected_files=("postgres.sql.gz" "redis_dump.rdb" "minio_config.json" "configs.tar.gz" "scripts.tar.gz"
  "manifest.txt")
    missing_files=()

    for file in "${expected_files[@]}"; do
        if [ ! -f "$backup_dir/$file" ]; then
            missing_files+=("$file")
        fi
    done

    if [ ${#missing_files[@]} -eq 0 ]; then
        echo -e "${GREEN}‚úÖ All files present in $backup_name${NC}"
        echo "[$DATE] All files present in $backup_name" >> "$VERIFICATION_LOG"

        # Verify PostgreSQL backup integrity
        if gzip -t "$backup_dir/postgres.sql.gz" 2>/dev/null; then
            echo -e "${GREEN}‚úÖ PostgreSQL backup integrity verified${NC}"
            echo "[$DATE] PostgreSQL backup integrity verified for $backup_name" >> "$VERIFICATION_LOG"
        else
            echo -e "${RED}‚ùå PostgreSQL backup integrity check failed${NC}"
            echo "[$DATE] PostgreSQL backup integrity check failed for $backup_name" >> "$VERIFICATION_LOG"
        fi

        # Verify Redis backup integrity
        if [ -f "$backup_dir/redis_dump.rdb" ]; then
            if file "$backup_dir/redis_dump.rdb" | grep -q "data"; then
                echo -e "${GREEN}‚úÖ Redis backup integrity verified${NC}"
                echo "[$DATE] Redis backup integrity verified for $backup_name" >> "$VERIFICATION_LOG"
            else
                echo -e "${RED}‚ùå Redis backup integrity check failed${NC}"
                echo "[$DATE] Redis backup integrity check failed for $backup_name" >> "$VERIFICATION_LOG"
            fi
        fi
    else
        echo -e "${RED}‚ùå Missing files in $backup_name: ${missing_files[*]}${NC}"
        echo "[$DATE] Missing files in $backup_name: ${missing_files[*]}" >> "$VERIFICATION_LOG"
    fi

    echo "----------------------------------------" >> "$VERIFICATION_LOG"
done

echo -e "${GREEN}üéâ Backup verification completed${NC}"
echo "[$DATE] Backup verification completed" >> "$VERIFICATION_LOG"

```

## 3. Recovery Point Objectives (RPO)

### 3.1 RPO Definition and Targets

The M365 RAG System defines the following Recovery Point Objectives:

| Data Component | RPO Target | Backup Frequency | Retention Period |
|----------------|------------|------------------|------------------|
| Elasticsearch Data | 1 hour | Continuous (WAL archiving) | 30 days |
| PostgreSQL Data | 1 hour | Continuous (WAL archiving) | 30 days |
| Redis Data | 4 hours | Every 4 hours | 7 days |
| MinIO Data | 24 hours | Daily | 30 days |
| Configuration Files | 24 hours | Daily | 90 days |
| Application Code | 24 hours | Daily | 90 days |

### 3.2 Continuous Data Protection

#### PostgreSQL WAL Archiving

```bash

# Configure PostgreSQL for WAL archiving

sudo nano /data/m365-rag/config/postgresql/postgresql.conf

```

```conf

# WAL Archiving Configuration

wal_level = replica
archive_mode = on
archive_command = 'cp %p /secure-backup/wal/%f'
max_wal_senders = 3
wal_keep_size = 1GB

```

#### Elasticsearch Snapshotting

```bash

# Create hourly Elasticsearch snapshot script

sudo nano /usr/local/bin/elasticsearch-hourly-snapshot.sh

```

```bash

#!/bin/bash

# Hourly Elasticsearch Snapshot Script

# Configuration (7)

ES_HOST="localhost:9200"
ES_USER="elastic"
ES_PASSWORD="${ELASTIC_PASSWORD:-changeme}"
DATE=$(date +%Y%m%d_%H%M)

# Colors for output (7)

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo -e "${GREEN}üîÑ Creating hourly Elasticsearch snapshot - $DATE${NC}"

# Create snapshot

curl -X PUT "https://$ES_HOST/_snapshot/backup/hourly_$DATE?wait_for_completion=true" \
    -u "$ES_USER:$ES_PASSWORD" \
    -H 'Content-Type: application/json' \
    -d '{
        "indices": "*",
        "ignore_unavailable": true,
        "include_global_state": false
    }' || echo -e "${RED}‚ùå Elasticsearch snapshot failed${NC}"

# Clean up old hourly snapshots (keep last 24)

echo -e "${YELLOW}üßπ Cleaning up old hourly snapshots...${NC}"
curl -X GET "https://$ES_HOST/_snapshot/backup/_all" \
    -u "$ES_USER:$ES_PASSWORD" | \
jq -r '.snapshots[] | select(.snapshot | startswith("hourly_")) | .snapshot' | \
sort | \
head -n -24 | \
while read snapshot; do
    echo -e "${YELLOW}üóëÔ∏è  Deleting old snapshot: $snapshot${NC}"
    curl -X DELETE "https://$ES_HOST/_snapshot/backup/$snapshot" \
        -u "$ES_USER:$ES_PASSWORD"
done

echo -e "${GREEN}üéâ Hourly Elasticsearch snapshot completed${NC}"

```

#### Redis Periodic Backup

```bash

# Create Redis backup script

sudo nano /usr/local/bin/redis-periodic-backup.sh

```

```bash

#!/bin/bash

# Periodic Redis Backup Script

# Configuration (8)

BACKUP_DIR="/secure-backup/m365-rag/redis"
DATE=$(date +%Y%m%d_%H%M)

# Colors for output (8)

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo -e "${GREEN}üîÑ Creating periodic Redis backup - $DATE${NC}"

# Create backup directory (2)

mkdir -p "$BACKUP_DIR"

# Trigger Redis save

docker exec redis redis-cli SAVE

# Copy dump file

docker cp redis:/data/dump.rdb "$BACKUP_DIR/dump_$DATE.rdb"

# Compress backup

gzip "$BACKUP_DIR/dump_$DATE.rdb"

# Encrypt backup

gpg --encrypt --recipient backup@m365-rag.local --output "$BACKUP_DIR/dump_$DATE.rdb.gz.gpg" "$BACKUP_DIR/dump_$DATE.rdb
  .gz"

# Remove unencrypted files

rm "$BACKUP_DIR/dump_$DATE.rdb.gz"

# Clean up old backups (keep last 42 - 7 days of 4-hour backups)

echo -e "${YELLOW}üßπ Cleaning up old Redis backups...${NC}"
find "$BACKUP_DIR" -name "dump_*.rdb.gz.gpg" -mtime +7 -delete 2>/dev/null || true

echo -e "${GREEN}üéâ Periodic Redis backup completed${NC}"

```

### 3.3 RPO Monitoring and Reporting

#### RPO Compliance Dashboard

```bash

# Create RPO monitoring script

sudo nano /usr/local/bin/rpo-monitor.sh

```

```bash

#!/bin/bash

# RPO Monitoring Script

# Configuration (9)

PROJECT_DIR="/data/m365-rag"
BACKUP_DIR="/secure-backup/m365-rag"
LOG_FILE="/var/log/rpo-monitor.log"
DATE=$(date +%Y%m%d_%H%M%S)

# Colors for output (9)

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo "[$DATE] Starting RPO compliance check" >> "$LOG_FILE"

# Check PostgreSQL RPO

echo -e "${YELLOW}üìä Checking PostgreSQL RPO compliance...${NC}"
latest_pg_backup=$(find "$BACKUP_DIR" -name "postgres.sql.gz" -printf '%T@ %p\n' | sort -n | tail -1 | cut -d' ' -f2-)
if [ -n "$latest_pg_backup" ]; then
    pg_backup_time=$(stat -c %Y "$latest_pg_backup")
    current_time=$(date +%s)
    pg_rpo=$((current_time - pg_backup_time))

    if [ "$pg_rpo" -le 3600 ]; then  # 1 hour
        echo -e "${GREEN}‚úÖ PostgreSQL RPO compliant: ${pg_rpo} seconds${NC}"
        echo "[$DATE] PostgreSQL RPO compliant: ${pg_rpo} seconds" >> "$LOG_FILE"
    else
        echo -e "${RED}‚ùå PostgreSQL RPO violation: ${pg_rpo} seconds${NC}"
        echo "[$DATE] PostgreSQL RPO violation: ${pg_rpo} seconds" >> "$LOG_FILE"
    fi
fi

# Check Redis RPO

echo -e "${YELLOW}üìä Checking Redis RPO compliance...${NC}"
latest_redis_backup=$(find "$BACKUP_DIR/redis" -name "dump_*.rdb.gz.gpg" -printf '%T@ %p\n' | sort -n | tail -1 | cut
  -d' ' -f2-)
if [ -n "$latest_redis_backup" ]; then
    redis_backup_time=$(stat -c %Y "$latest_redis_backup")
    current_time=$(date +%s)
    redis_rpo=$((current_time - redis_backup_time))

    if [ "$redis_rpo" -le 14400 ]; then  # 4 hours
        echo -e "${GREEN}‚úÖ Redis RPO compliant: ${redis_rpo} seconds${NC}"
        echo "[$DATE] Redis RPO compliant: ${redis_rpo} seconds" >> "$LOG_FILE"
    else
        echo -e "${RED}‚ùå Redis RPO violation: ${redis_rpo} seconds${NC}"
        echo "[$DATE] Redis RPO violation: ${redis_rpo} seconds" >> "$LOG_FILE"
    fi
fi

# Check MinIO RPO

echo -e "${YELLOW}üìä Checking MinIO RPO compliance...${NC}"
latest_minio_backup=$(find "$BACKUP_DIR" -name "minio_config.json" -printf '%T@ %p\n' | sort -n | tail -1 | cut -d' '
  -f2-)
if [ -n "$latest_minio_backup" ]; then
    minio_backup_time=$(stat -c %Y "$latest_minio_backup")
    current_time=$(date +%s)
    minio_rpo=$((current_time - minio_backup_time))

    if [ "$minio_rpo" -le 86400 ]; then  # 24 hours
        echo -e "${GREEN}‚úÖ MinIO RPO compliant: ${minio_rpo} seconds${NC}"
        echo "[$DATE] MinIO RPO compliant: ${minio_rpo} seconds" >> "$LOG_FILE"
    else
        echo -e "${RED}‚ùå MinIO RPO violation: ${minio_rpo} seconds${NC}"
        echo "[$DATE] MinIO RPO violation: ${minio_rpo} seconds" >> "$LOG_FILE"
    fi
fi

echo -e "${GREEN}üéâ RPO compliance check completed${NC}"
echo "[$DATE] RPO compliance check completed" >> "$LOG_FILE"

```

## 4. Recovery Time Objectives (RTO)

### 4.1 RTO Definition and Targets

The M365 RAG System defines the following Recovery Time Objectives:

| Recovery Scenario | RTO Target | Priority Level |
|-------------------|------------|----------------|
| Full System Recovery | 4 hours | High |
| Database Recovery | 2 hours | High |
| Application Recovery | 1 hour | Medium |
| Configuration Recovery | 30 minutes | Low |
| Single Service Recovery | 15 minutes | Low |

### 4.2 Automated Recovery Procedures

#### Fast Recovery Script

```bash

# Create fast recovery script

sudo nano /usr/local/bin/fast-recover.sh

```

```bash

#!/bin/bash

# Fast Recovery Script for M365 RAG System

# Configuration (10)

BACKUP_DIR="/secure-backup/m365-rag"
PROJECT_DIR="/data/m365-rag"
DATE=${1:-$(ls -1t "$BACKUP_DIR" | head -1)}

# Colors for output (10)

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Check if backup date is provided

if [ -z "$DATE" ]; then
    echo -e "${RED}‚ùå Usage: $0 <backup_date>${NC}"
    echo -e "${YELLOW}Available backups:${NC}"
    ls -1 "$BACKUP_DIR"
    exit 1
fi

# Verify backup exists

if [ ! -d "$BACKUP_DIR/$DATE" ]; then
    echo -e "${RED}‚ùå Backup directory not found: $BACKUP_DIR/$DATE${NC}"
    exit 1
fi

echo -e "${YELLOW}‚ö†Ô∏è  WARNING: This will restore data from backup $DATE${NC}"
echo -e "${YELLOW}‚ö†Ô∏è  All current data will be replaced!${NC}"
echo ""
read -p "Are you sure you want to continue? (yes/no): " CONFIRM

if [ "$CONFIRM" != "yes" ]; then
    echo "Recovery cancelled."
    exit 0
fi

echo -e "${GREEN}üîÑ Starting fast recovery from backup: $DATE${NC}"

# 1. Stop all services

echo -e "${YELLOW}üõë Stopping services...${NC}"
cd "$PROJECT_DIR"
docker compose stop

# 2. Restore PostgreSQL

echo -e "${YELLOW}üóÑÔ∏è  Restoring PostgreSQL...${NC}"
if [ -f "$BACKUP_DIR/$DATE/postgres.sql.gz" ]; then
    docker compose start postgres
    sleep 10
    gunzip < "$BACKUP_DIR/$DATE/postgres.sql.gz" | docker exec -i postgres psql -U raguser m365_rag
    echo -e "${GREEN}‚úÖ PostgreSQL restored${NC}"
else
    echo -e "${RED}‚ùå PostgreSQL backup file not found${NC}"
fi

# 3. Restore Redis

echo -e "${YELLOW}üíæ Restoring Redis...${NC}"
if [ -f "$BACKUP_DIR/$DATE/redis_dump.rdb" ]; then
    docker compose start redis
    sleep 5
    docker cp "$BACKUP_DIR/$DATE/redis_dump.rdb" redis:/data/dump.rdb
    docker compose restart redis
    echo -e "${GREEN}‚úÖ Redis restored${NC}"
else
    echo -e "${RED}‚ùå Redis backup file not found${NC}"
fi

# 4. Restore Elasticsearch

echo -e "${YELLOW}üìä Restoring Elasticsearch...${NC}"
docker compose start elasticsearch
sleep 20
docker exec elasticsearch curl -k -X POST "https://localhost:9200/_snapshot/backup/$DATE/_restore" \
    -u "elastic:$ELASTIC_PASSWORD" \
    -H 'Content-Type: application/json' \
    -d '{
        "indices": "*",
        "ignore_unavailable": true,
        "include_global_state": false
    }' || echo -e "${RED}‚ùå Elasticsearch restore failed${NC}"

# 5. Restore configurations

echo -e "${YELLOW}‚öôÔ∏è  Restoring configuration files...${NC}"
if [ -f "$BACKUP_DIR/$DATE/configs.tar.gz" ]; then
    tar -xzf "$BACKUP_DIR/$DATE/configs.tar.gz" -C "$PROJECT_DIR/"
    echo -e "${GREEN}‚úÖ Configurations restored${NC}"
else
    echo -e "${RED}‚ùå Config backup file not found${NC}"
fi

# 6. Start all services

echo -e "${YELLOW}üöÄ Starting all services...${NC}"
docker compose up -d

# Wait for services to be healthy

echo -e "${YELLOW}‚è≥ Waiting for services to be healthy...${NC}"
sleep 30

# Verify services

echo -e "${YELLOW}üîç Verifying services...${NC}"
docker compose ps

echo -e "${GREEN}‚úÖ Fast recovery completed!${NC}"
echo -e "${GREEN}üìÅ Restored from: $BACKUP_DIR/$DATE${NC}"
echo ""
echo -e "${YELLOW}Next steps:${NC}"
echo "1. Verify services are running: docker compose ps"
echo "2. Check API health: curl http://localhost:8000/health"
echo "3. Access RAGFlow UI: http://YOUR_SERVER_IP:9380"
echo "4. Check Elasticsearch: curl -u elastic:PASSWORD https://localhost:9200/_cluster/health"

```

#### Selective Service Recovery

```bash

# Create selective recovery script

sudo nano /usr/local/bin/selective-recover.sh

```

```bash

#!/bin/bash

# Selective Service Recovery Script

# Configuration (11)

BACKUP_DIR="/secure-backup/m365-rag"
PROJECT_DIR="/data/m365-rag"
SERVICE=${1}
DATE=${2:-$(ls -1t "$BACKUP_DIR" | head -1)}

# Colors for output (11)

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Check if service and backup date are provided

if [ -z "$SERVICE" ] || [ -z "$DATE" ]; then
    echo -e "${RED}‚ùå Usage: $0 <service> <backup_date>${NC}"
    echo -e "${YELLOW}Services: elasticsearch, postgresql, redis, minio, config${NC}"
    echo -e "${YELLOW}Available backups:${NC}"
    ls -1 "$BACKUP_DIR"
    exit 1
fi

# Verify backup exists (2)

if [ ! -d "$BACKUP_DIR/$DATE" ]; then
    echo -e "${RED}‚ùå Backup directory not found: $BACKUP_DIR/$DATE${NC}"
    exit 1
fi

echo -e "${GREEN}üîÑ Starting selective recovery of $SERVICE from backup: $DATE${NC}"

case "$SERVICE" in
    elasticsearch)
        echo -e "${YELLOW}üìä Restoring Elasticsearch...${NC}"
        cd "$PROJECT_DIR"
        docker compose start elasticsearch
        sleep 20
        docker exec elasticsearch curl -k -X POST "https://localhost:9200/_snapshot/backup/$DATE/_restore" \
            -u "elastic:$ELASTIC_PASSWORD" \
            -H 'Content-Type: application/json' \
            -d '{
                "indices": "*",
                "ignore_unavailable": true,
                "include_global_state": false
            }' || echo -e "${RED}‚ùå Elasticsearch restore failed${NC}"
        echo -e "${GREEN}‚úÖ Elasticsearch restored${NC}"
        ;;
    postgresql)
        echo -e "${YELLOW}üóÑÔ∏è  Restoring PostgreSQL...${NC}"
        cd "$PROJECT_DIR"
        if [ -f "$BACKUP_DIR/$DATE/postgres.sql.gz" ]; then
            docker compose start postgres
            sleep 10
            gunzip < "$BACKUP_DIR/$DATE/postgres.sql.gz" | docker exec -i postgres psql -U raguser m365_rag
            echo -e "${GREEN}‚úÖ PostgreSQL restored${NC}"
        else
            echo -e "${RED}‚ùå PostgreSQL backup file not found${NC}"
        fi
        ;;
    redis)
        echo -e "${YELLOW}üíæ Restoring Redis...${NC}"
        cd "$PROJECT_DIR"
        if [ -f "$BACKUP_DIR/$DATE/redis_dump.rdb" ]; then
            docker compose start redis
            sleep 5
            docker cp "$BACKUP_DIR/$DATE/redis_dump.rdb" redis:/data/dump.rdb
            docker compose restart redis
            echo -e "${GREEN}‚úÖ Redis restored${NC}"
        else
            echo -e "${RED}‚ùå Redis backup file not found${NC}"
        fi
        ;;
    minio)
        echo -e "${YELLOW}üì¶ Restoring MinIO...${NC}"
        echo -e "${YELLOW}‚ö†Ô∏è  MinIO restoration requires manual steps${NC}"
        echo -e "${YELLOW}üìã Instructions:${NC}"
        echo "1. Stop MinIO service: docker compose stop minio"
        echo "2. Restore data from backup if available"
        echo "3. Start MinIO service: docker compose start minio"
        ;;
    config)
        echo -e "${YELLOW}‚öôÔ∏è  Restoring configuration files...${NC}"
        cd "$PROJECT_DIR"
        if [ -f "$BACKUP_DIR/$DATE/configs.tar.gz" ]; then
            tar -xzf "$BACKUP_DIR/$DATE/configs.tar.gz" -C "$PROJECT_DIR/"
            echo -e "${GREEN}‚úÖ Configurations restored${NC}"
        else
            echo -e "${RED}‚ùå Config backup file not found${NC}"
        fi
        ;;
    *)
        echo -e "${RED}‚ùå Unknown service: $SERVICE${NC}"
        echo -e "${YELLOW}Available services: elasticsearch, postgresql, redis, minio, config${NC}"
        exit 1
        ;;
esac

echo -e "${GREEN}‚úÖ Selective recovery of $SERVICE completed!${NC}"

```

### 4.3 Recovery Testing Procedures

#### Monthly Recovery Testing

```bash

# Create recovery testing script

sudo nano /usr/local/bin/test-recovery.sh

```

```bash

#!/bin/bash

# Recovery Testing Script

# Configuration (12)

TEST_DIR="/tmp/m365-rag-recovery-test"
BACKUP_DIR="/secure-backup/m365-rag"
PROJECT_DIR="/data/m365-rag"
DATE=$(date +%Y%m%d_%H%M%S)

# Colors for output (12)

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo -e "${GREEN}üß™ Starting recovery test - $DATE${NC}"

# Create test environment

mkdir -p "$TEST_DIR"
cd "$TEST_DIR"

# Copy latest backup for testing

latest_backup=$(ls -1t "$BACKUP_DIR" | head -1)
if [ -z "$latest_backup" ]; then
    echo -e "${RED}‚ùå No backups found${NC}"
    exit 1
fi

echo -e "${YELLOW}üìã Copying backup for testing...${NC}"
cp -r "$BACKUP_DIR/$latest_backup" "$TEST_DIR/backup"

# Create test docker-compose.yml

cat > "$TEST_DIR/docker-compose.yml" <<EOF
version: '3.8'

networks:
  test-network:
    driver: bridge

volumes:
  test-es-data:
  test-pg-data:
  test-redis-data:

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0
    environment:

      - discovery.type=single-node
      - xpack.security.enabled=false

    volumes:

      - test-es-data:/usr/share/elasticsearch/data

    networks:

      - test-network

  postgres:
    image: pgvector/pgvector:pg16
    environment:

      - POSTGRES_DB=m365_rag
      - POSTGRES_USER=raguser
      - POSTGRES_PASSWORD=changeme

    volumes:

      - test-pg-data:/var/lib/postgresql/data

    networks:

      - test-network

  redis:
    image: redis:7-alpine
    volumes:

      - test-redis-data:/data

    networks:

      - test-network

EOF

# Start test environment

echo -e "${YELLOW}üöÄ Starting test environment...${NC}"
docker compose up -d

# Wait for services

echo -e "${YELLOW}‚è≥ Waiting for services to start...${NC}"
sleep 30

# Test PostgreSQL recovery

echo -e "${YELLOW}üóÑÔ∏è  Testing PostgreSQL recovery...${NC}"
if [ -f "$TEST_DIR/backup/postgres.sql.gz" ]; then
    gunzip < "$TEST_DIR/backup/postgres.sql.gz" | docker exec -i postgres psql -U raguser m365_rag
    echo -e "${GREEN}‚úÖ PostgreSQL recovery test passed${NC}"
else
    echo -e "${RED}‚ùå PostgreSQL backup not found${NC}"
fi

# Test Redis recovery

echo -e "${YELLOW}üíæ Testing Redis recovery...${NC}"
if [ -f "$TEST_DIR/backup/redis_dump.rdb" ]; then
    docker cp "$TEST_DIR/backup/redis_dump.rdb" redis:/data/dump.rdb
    docker compose restart redis
    sleep 5
    docker exec redis redis-cli ping
    echo -e "${GREEN}‚úÖ Redis recovery test passed${NC}"
else
    echo -e "${RED}‚ùå Redis backup not found${NC}"
fi

# Clean up test environment

echo -e "${YELLOW}üßπ Cleaning up test environment...${NC}"
docker compose down -v
rm -rf "$TEST_DIR"

echo -e "${GREEN}üéâ Recovery testing completed${NC}"

```

## 5. Implementation Checklist

### 5.1 Secure Backup Storage

- [ ] Encrypted backup volume created and mounted
- [ ] Secure backup script implemented
- [ ] Off-site backup storage configured (Hetzner Storage Box)
- [ ] Cloud backup storage configured (AWS S3)
- [ ] Air-gapped archival process established
- [ ] Backup storage security tested

### 5.2 Backup Encryption

- [ ] GPG keys generated for backup encryption
- [ ] Public key distributed to backup systems
- [ ] Private key securely stored
- [ ] Key rotation policy implemented
- [ ] Backup integrity verification process established
- [ ] Encryption testing completed

### 5.3 Recovery Point Objectives

- [ ] RPO targets defined for all data components
- [ ] Continuous data protection implemented for critical data
- [ ] Hourly snapshotting configured for Elasticsearch
- [ ] WAL archiving configured for PostgreSQL
- [ ] Periodic backups configured for Redis
- [ ] RPO monitoring dashboard created
- [ ] RPO compliance testing completed

### 5.4 Recovery Time Objectives

- [ ] RTO targets defined for all recovery scenarios
- [ ] Fast recovery script implemented
- [ ] Selective service recovery script implemented
- [ ] Recovery testing procedures established
- [ ] Monthly recovery testing scheduled
- [ ] RTO compliance testing completed

## 6. Monitoring and Maintenance

### 6.1 Backup Monitoring

#### Backup Success Monitoring

```bash

# Create backup monitoring script

sudo nano /usr/local/bin/monitor-backups.sh

```

```bash

#!/bin/bash

# Backup Monitoring Script

# Configuration (13)

BACKUP_DIR="/secure-backup/m365-rag"
LOG_FILE="/var/log/backup-monitor.log"
DATE=$(date +%Y%m%d_%H%M%S)

# Colors for output (13)

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo "[$DATE] Starting backup monitoring" >> "$LOG_FILE"

# Check if daily backup exists

today=$(date +%Y%m%d)
daily_backup=$(find "$BACKUP_DIR" -name "${today}*" -type d)

if [ -n "$daily_backup" ]; then
    echo -e "${GREEN}‚úÖ Daily backup found: $daily_backup${NC}"
    echo "[$DATE] Daily backup found: $daily_backup" >> "$LOG_FILE"

    # Check backup completeness
    expected_files=("postgres.sql.gz" "redis_dump.rdb" "minio_config.json" "configs.tar.gz" "scripts.tar.gz")
    missing_files=()

    for file in "${expected_files[@]}"; do
        if [ ! -f "$daily_backup/$file" ]; then
            missing_files+=("$file")
        fi
    done

    if [ ${#missing_files[@]} -eq 0 ]; then
        echo -e "${GREEN}‚úÖ Daily backup is complete${NC}"
        echo "[$DATE] Daily backup is complete" >> "$LOG_FILE"
    else
        echo -e "${RED}‚ùå Daily backup is incomplete. Missing: ${missing_files[*]}${NC}"
        echo "[$DATE] Daily backup is incomplete. Missing: ${missing_files[*]}" >> "$LOG_FILE"
    fi
else
    echo -e "${RED}‚ùå No daily backup found for $today${NC}"
    echo "[$DATE] No daily backup found for $today" >> "$LOG_FILE"
fi

# Check backup encryption

latest_backup=$(ls -1t "$BACKUP_DIR" | head -1)
if [ -n "$latest_backup" ]; then
    encrypted_files=$(find "$BACKUP_DIR/$latest_backup" -name "*.gpg" | wc -l)
    if [ "$encrypted_files" -gt 0 ]; then
        echo -e "${GREEN}‚úÖ Backup encryption verified${NC}"
        echo "[$DATE] Backup encryption verified" >> "$LOG_FILE"
    else
        echo -e "${YELLOW}‚ö†Ô∏è  No encrypted files found in latest backup${NC}"
        echo "[$DATE] No encrypted files found in latest backup" >> "$LOG_FILE"
    fi
fi

echo -e "${GREEN}üéâ Backup monitoring completed${NC}"
echo "[$DATE] Backup monitoring completed" >> "$LOG_FILE"

```

### 6.2 Scheduled Maintenance Tasks

#### Monthly Maintenance Script

```bash

# Create monthly maintenance script

sudo nano /usr/local/bin/monthly-maintenance.sh

```

```bash

#!/bin/bash

# Monthly Maintenance Script for M365 RAG System

# Configuration (14)

LOG_FILE="/var/log/monthly-maintenance.log"
DATE=$(date +%Y%m%d_%H%M%S)

# Colors for output (14)

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo "[$DATE] Starting monthly maintenance" >> "$LOG_FILE"

# 1. Rotate backup encryption keys

echo -e "${YELLOW}üîë Rotating backup encryption keys...${NC}"
/usr/local/bin/rotate-backup-keys.sh >> "$LOG_FILE" 2>&1

# 2. Verify all backups

echo -e "${YELLOW}üîç Verifying all backups...${NC}"
/usr/local/bin/verify-encrypted-backups.sh >> "$LOG_FILE" 2>&1

# 3. Test recovery procedures

echo -e "${YELLOW}üß™ Testing recovery procedures...${NC}"
/usr/local/bin/test-recovery.sh >> "$LOG_FILE" 2>&1

# 4. Check RPO compliance

echo -e "${YELLOW}üìä Checking RPO compliance...${NC}"
/usr/local/bin/rpo-monitor.sh >> "$LOG_FILE" 2>&1

# 5. Update system packages

echo -e "${YELLOW}üîÑ Updating system packages...${NC}"
apt update && apt upgrade -y >> "$LOG_FILE" 2>&1

# 6. Clean up old logs

echo -e "${YELLOW}üßπ Cleaning up old logs...${NC}"
find /var/log -name "*.log" -mtime +90 -delete 2>/dev/null || true

echo -e "${GREEN}üéâ Monthly maintenance completed${NC}"
echo "[$DATE] Monthly maintenance completed" >> "$LOG_FILE"

```

## 7. Disaster Recovery Testing Plan

### 7.1 Quarterly Disaster Recovery Tests

#### Full System Recovery Test

1. **Preparation** (1 week before test):
   - Notify stakeholders of scheduled test
   - Verify backup integrity
   - Prepare test environment

2. **Execution** (Test day):
   - Simulate complete system failure
   - Execute full recovery procedure
   - Validate recovered system functionality
   - Document recovery time and issues

3. **Post-Test** (1 day after test):
   - Restore production system
   - Update disaster recovery documentation
   - Address identified issues

#### Component Failure Tests

1. **Database Failure**:
   - Simulate PostgreSQL failure
   - Execute database recovery
   - Validate data integrity

2. **Storage Failure**:
   - Simulate MinIO failure
   - Execute storage recovery
   - Validate file accessibility

3. **Network Failure**:
   - Simulate network partition
   - Execute service recovery
   - Validate service availability

### 7.2 Annual Disaster Recovery Audit

#### Audit Checklist

- [ ] Review and update RPO/RTO targets
- [ ] Verify backup encryption keys
- [ ] Test off-site backup accessibility
- [ ] Validate air-gapped backup integrity
- [ ] Review disaster recovery documentation
- [ ] Update contact information and procedures
- [ ] Conduct tabletop exercise with team

This disaster recovery and backup security plan ensures the M365 RAG System can recover from various failure scenarios
while maintaining data security and compliance requirements. The plan should be reviewed and tested regularly to
  ensure its effectiveness.
